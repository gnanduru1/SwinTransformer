{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "Number of GPUs available: 1\n",
      "\n",
      "Details for GPU 0:\n",
      "Name: Tesla V100-SXM2-32GB\n",
      "Total Memory: 31.73 GB\n",
      "Multi-Processor Count: 80\n",
      "Compute Capability: (7, 0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    \n",
    "    # Number of GPUs available\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "    \n",
    "    for i in range(num_gpus):\n",
    "        print(f\"\\nDetails for GPU {i}:\")\n",
    "        print(f\"Name: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"Total Memory: {torch.cuda.get_device_properties(i).total_memory / (1024**3):.2f} GB\")\n",
    "        print(f\"Multi-Processor Count: {torch.cuda.get_device_properties(i).multi_processor_count}\")\n",
    "        print(f\"Compute Capability: {torch.cuda.get_device_capability(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import SwinModel\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "data = np.load('2023-11-15-cine-myo-masks-and-TOS.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, desired_num_frames=32):\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        self.desired_num_frames = desired_num_frames\n",
    "        for item in data:\n",
    "            mask_volume = item['cine_lv_myo_masks_cropped']  # Shape: (H, W, n_frames)\n",
    "            tos = item['TOS']  # Shape: (126,)\n",
    "            self.inputs.append(mask_volume)\n",
    "            self.targets.append(tos)\n",
    "            \n",
    "        self.resize = transforms.Resize((224, 224))\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.to_pil = transforms.ToPILImage()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        mask_volume = self.inputs[idx]  # Shape: (H, W, n_frames)\n",
    "        tos = self.targets[idx]  # Shape: (126,)\n",
    "        \n",
    "        # Rearrange mask_volume to (n_frames, H, W)\n",
    "        mask_volume = mask_volume.transpose(2, 0, 1)  # Now shape is (n_frames, H, W)\n",
    "        \n",
    "        # Ensure the number of frames is desired_num_frames\n",
    "        num_frames = mask_volume.shape[0]\n",
    "        desired_num_frames = self.desired_num_frames\n",
    "        if num_frames < desired_num_frames:\n",
    "            # Pad with zeros (blank frames)\n",
    "            pad_size = desired_num_frames - num_frames\n",
    "            pad_frames = np.zeros((pad_size, mask_volume.shape[1], mask_volume.shape[2]))\n",
    "            mask_volume = np.concatenate((mask_volume, pad_frames), axis=0)\n",
    "        elif num_frames > desired_num_frames:\n",
    "            # Sample frames evenly\n",
    "            indices = np.linspace(0, num_frames - 1, desired_num_frames, dtype=int)\n",
    "            mask_volume = mask_volume[indices]\n",
    "        # Now mask_volume has shape (desired_num_frames, H, W)\n",
    "        \n",
    "        # Process each frame\n",
    "        frames = []\n",
    "        for frame in mask_volume:\n",
    "            frame = frame.astype(np.uint8)  # Convert to uint8\n",
    "            frame_pil = self.to_pil(frame)\n",
    "            frame_resized = self.resize(frame_pil)\n",
    "            frame_tensor = self.to_tensor(frame_resized)\n",
    "            # Repeat the grayscale channel to make it 3 channels\n",
    "            frame_tensor = frame_tensor.repeat(3, 1, 1)\n",
    "            frames.append(frame_tensor)\n",
    "        \n",
    "        # Stack frames to create a tensor of shape (desired_num_frames, 3, 224, 224)\n",
    "        frames_tensor = torch.stack(frames)  # Shape: (desired_num_frames, 3, 224, 224)\n",
    "        \n",
    "        # Convert tos to tensor\n",
    "        tos_tensor = torch.tensor(tos, dtype=torch.float32)\n",
    "        \n",
    "        return frames_tensor, tos_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and evaluation sets\n",
    "dataset = MyDataset(data, desired_num_frames=32)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "eval_size = len(dataset) - train_size\n",
    "train_dataset, eval_dataset = random_split(dataset, [train_size, eval_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Regression Model\n",
    "class SwinRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SwinRegressionModel, self).__init__()\n",
    "        self.swin = SwinModel.from_pretrained('microsoft/swin-base-patch4-window7-224')\n",
    "        self.config = self.swin.config\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 126)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, desired_num_frames, 3, 224, 224)\n",
    "        batch_size, n_frames, C, H, W = x.size()\n",
    "        x = x.view(batch_size * n_frames, C, H, W)  # Merge batch and frames\n",
    "        outputs = self.swin(x)\n",
    "        # outputs.last_hidden_state: (batch_size * n_frames, num_patches, hidden_size)\n",
    "        # Pool over spatial dimensions (mean pooling)\n",
    "        hidden_states = outputs.last_hidden_state.mean(dim=1)  # (batch_size * n_frames, hidden_size)\n",
    "        # Reshape back to (batch_size, n_frames, hidden_size)\n",
    "        hidden_states = hidden_states.view(batch_size, n_frames, -1)\n",
    "        # Aggregate over frames (e.g., average)\n",
    "        aggregated_features = hidden_states.mean(dim=1)  # (batch_size, hidden_size)\n",
    "        regression_output = self.fc(aggregated_features)  # (batch_size, 126)\n",
    "        return regression_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model, Loss Function, and Optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SwinRegressionModel().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 26/26 [00:33<00:00,  1.30s/batch, Batch Loss=921]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Completed. Average Training Loss: 1129.0148\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 26/26 [00:33<00:00,  1.30s/batch, Batch Loss=781]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Completed. Average Training Loss: 871.4726\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 26/26 [00:34<00:00,  1.32s/batch, Batch Loss=1.19e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Completed. Average Training Loss: 704.8333\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 26/26 [00:34<00:00,  1.33s/batch, Batch Loss=169]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Completed. Average Training Loss: 553.8599\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 26/26 [00:34<00:00,  1.31s/batch, Batch Loss=333]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Completed. Average Training Loss: 465.1299\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 26/26 [00:34<00:00,  1.32s/batch, Batch Loss=299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Completed. Average Training Loss: 398.0705\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 26/26 [00:34<00:00,  1.31s/batch, Batch Loss=122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Completed. Average Training Loss: 348.0300\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 26/26 [00:34<00:00,  1.32s/batch, Batch Loss=147] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Completed. Average Training Loss: 313.7200\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 26/26 [00:34<00:00,  1.32s/batch, Batch Loss=214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Completed. Average Training Loss: 290.4711\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 26/26 [00:34<00:00,  1.31s/batch, Batch Loss=439]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Completed. Average Training Loss: 278.2290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch+1}\", unit=\"batch\")\n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # outputs: (batch_size, 126)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"Batch Loss\": loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1} Completed. Average Training Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute R^2 Score on Evaluation Data\n",
    "def compute_r2_score(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            all_predictions.append(outputs.cpu())\n",
    "            all_targets.append(targets.cpu())\n",
    "    \n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    \n",
    "    mean_targets = torch.mean(all_targets, dim=0)\n",
    "    total_sum_of_squares = torch.sum((all_targets - mean_targets) ** 2)\n",
    "    residual_sum_of_squares = torch.sum((all_targets - all_predictions) ** 2)\n",
    "    r2 = 1 - (residual_sum_of_squares / total_sum_of_squares)\n",
    "    \n",
    "    return r2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final R^2 Score on Evaluation Dataset: -0.0075\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "final_r2_score = compute_r2_score(model, eval_dataloader, device)\n",
    "print(f\"\\nFinal R^2 Score on Evaluation Dataset: {final_r2_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
